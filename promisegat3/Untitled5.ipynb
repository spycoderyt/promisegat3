{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENkro1sgWv4y"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Ys3XU2XT2k",
        "outputId": "dec4ea55-4202-433f-be5c-4900013657b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.5)\n",
            "Collecting bio\n",
            "  Downloading bio-1.6.2-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.41.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Collecting biopython>=1.80 (from bio)\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bio) (4.66.2)\n",
            "Collecting mygene (from bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bio) (1.5.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from bio) (1.8.1)\n",
            "Collecting gprofiler-official (from bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->bio)\n",
            "  Downloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bio) (2023.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->bio) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->bio) (23.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Installing collected packages: biopython, gprofiler-official, biothings-client, mygene, bio\n",
            "Successfully installed bio-1.6.2 biopython-1.83 biothings-client-0.3.1 gprofiler-official-1.0.0 mygene-3.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb rdkit bio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJQ1MYtTGuzD"
      },
      "source": [
        "#import data from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsb0xrfiGsfl",
        "outputId": "3f8d9576-086b-487c-a2dc-24d3e3bbebac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'promisegat3'...\n",
            "remote: Enumerating objects: 11770, done.\u001b[K\n",
            "remote: Counting objects: 100% (3295/3295), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3267/3267), done.\u001b[K\n",
            "remote: Total 11770 (delta 27), reused 3291 (delta 26), pack-reused 8475\u001b[K\n",
            "Receiving objects: 100% (11770/11770), 251.71 MiB | 13.98 MiB/s, done.\n",
            "Resolving deltas: 100% (1527/1527), done.\n",
            "Updating files: 100% (11712/11712), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/spycoderyt/promisegat3.git\n",
        "#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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxDZSqTLWWZB",
        "outputId": "e0cebd4b-509b-4f11-8265-18d49fc40694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cur dir = /Users/gino/promisegat3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if os.getcwd() == '/content':\n",
        "  os.chdir('promisegat3/promisegat3')\n",
        "print(f\"Cur dir = {os.getcwd()}\")\n",
        "\n",
        "using_targets_list = []\n",
        "with open('target_names.txt','r') as file:\n",
        "    for line in file:\n",
        "        folder_name = line.strip().replace('/', '_')\n",
        "        using_targets_list.append(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X9RUMUeeD5f",
        "outputId": "d0a37f66-f514-4299-e828-733236223a25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ed814366570>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "### Import Necessary Libraries ###\n",
        "import pickle\n",
        "import timeit\n",
        "import os\n",
        "import random\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "random.seed = 1234\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_VL2w8UWL8_"
      },
      "source": [
        "#use dlip files to create training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# def process_target_folder(target_name, inchikey_path, training_data_path,target_pdb_path):\n",
        "#     target_folder_cnt=0\n",
        "#     target_folder = os.path.join(target_pdb_path, target_name)\n",
        "#     print(f\"doing at {target_folder}\")\n",
        "#     if os.path.exists(target_folder):\n",
        "#         for file in os.listdir(target_folder):\n",
        "#             filepath = os.path.join(target_folder, file)\n",
        "#             write_to_output(inchikey_path, filepath, 1, training_data_path)\n",
        "#             print(f\"Writing to output for {inchikey_path} and {filepath}\")\n",
        "#             target_folder_cnt+=1\n",
        "#     return target_folder_cnt\n",
        "\n",
        "# def process_other_folders(target_name, inchikey_path,  training_data_path, target_pdb_path):\n",
        "#     other_folder_cnt=0\n",
        "#     other_folders = get_other_folders(target_name, target_pdb_path)\n",
        "#     random_other_folders = random.sample(other_folders, 5)  # Randomly choose 5 other folders\n",
        "#     for other_folder in random_other_folders:\n",
        "#         other_folder_path = os.path.join(target_pdb_path, other_folder)\n",
        "#         files = os.listdir(other_folder_path)\n",
        "#         if files:  # Check if the list is not empty\n",
        "#             random_file = random.choice(files)\n",
        "#             filepath = os.path.join(other_folder_path, random_file)\n",
        "#             write_to_output(inchikey_path, filepath, 0, training_data_path)\n",
        "#             other_folder_cnt+=1\n",
        "#     return other_folder_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyXqBx5RX0wG"
      },
      "outputs": [],
      "source": [
        "\n",
        "extended_name_map = {\n",
        "    \"1-acylglycerol-3-phosphate O-acyltransferase ABHD5/Perilipin-5\": \"ABHD5\",\n",
        "    \"AR/unknown partner\": \"AR\",\n",
        "    \"Annexin A2/S100-A10\": \"Annexin A2\",\n",
        "    \"Aryl hydrocarbon receptor nuclear translocator/Endothelial PAS domain-containing protein 1\": \"Aryl hydrocarbon receptor nuclear translocator\",\n",
        "    \"BAZ2B/H4\": \"BAZ2B\",\n",
        "    \"BCL-like/BAX,BAK\": \"BCL-like\",\n",
        "    \"BCoR/BCL6\": \"BCoR\",\n",
        "    \"Beta-catenin/TCF\": \"Beta-catenin\",\n",
        "    \"Bromodomain/Histone\": \"Bromodomain\",\n",
        "    \"CD4/gp120\": \"CD4\",\n",
        "    \"CD80/CD28\": \"CD80\",\n",
        "    \"CREBBP/H4\": \"CREBBP\",\n",
        "    \"CRM1/Rev\": \"CRM1\",\n",
        "    \"Catenin beta-1/Transcription factor 7\": \"Catenin beta-1\",\n",
        "    \"Cyclin-dependent kinases regulatory subunit 1/S-phase kinase-associated protein 2\": \"Cyclin-dependent kinases regulatory subunit 1\",\n",
        "    \"Cyclophilins\": \"Cyclophilins\",\n",
        "    \"DCN1/UBE2M\": \"DCN1\",\n",
        "    \"E1/E2\": \"E1\",\n",
        "    \"ELF3/MED23\": \"ELF3\",\n",
        "    \"FAK/VEGFR3\": \"FAK\",\n",
        "    \"FKBP1A/FK506\": \"FKBP1A\",\n",
        "    \"GATA4/NKX2-5\": \"GATA4\",\n",
        "    \"Glucokinase/Glucokinase regulatory protein\": \"Glucokinase\",\n",
        "    \"Guanine nucleotide-binding protein G(i) subunit alpha-1/Regulator of G-protein signaling 12\": \"Guanine nucleotide-binding protein G(i) subunit alpha-1\",\n",
        "    \"HIF-1a/p300\": \"HIF-1a\",\n",
        "    \"HRAS/SOS1\": \"HRAS\",\n",
        "    \"IL2/IL2R\": \"IL2\",\n",
        "    \"INTEGRASE/LEDGF\": \"INTEGRASE\",\n",
        "    \"Importin subunit beta-1/Snurportin-1\": \"Importin subunit beta-1\",\n",
        "    \"Induced myeloid leukemia cell differentiation protein Mcl-1/Bcl-2-like protein 11\": \"Mcl-1\",\n",
        "    \"Integrins\": \"Integrins\",\n",
        "    \"Interferon-induced guanylate-binding protein 1/Serine/threonine-protein kinase pim-1\": \"Interferon-induced guanylate-binding protein 1\",\n",
        "    \"KEAP1/NRF2\": \"KEAP1\",\n",
        "    \"KRAS/SOS1\": \"KRAS\",\n",
        "    \"LEDGF/IN\": \"LEDGF\",\n",
        "    \"LFA/ICAM\": \"LFA\",\n",
        "    \"MDM4/P53\": \"MDM4\",\n",
        "    \"MENIN/MLL\": \"MENIN\",\n",
        "    \"MIF/CD74\": \"MIF\",\n",
        "    \"MKEAP1/MNRF2\": \"MKEAP1\",\n",
        "    \"MYC/MAX\": \"MYC\",\n",
        "    \"NCS-1/Ric8a\": \"NCS-1\",\n",
        "    \"NRP/VEGF\": \"NRP\",\n",
        "    \"Neuropilin-1/VEGF-A\": \"Neuropilin-1\",\n",
        "    \"P53/HDM2\": \"P53\",\n",
        "    \"PA/PB1\": \"PA\",\n",
        "    \"PB1-5/H3\": \"PB1-5\",\n",
        "    \"PCSK9/LDLR\": \"PCSK9\",\n",
        "    \"Perilipin-1/ABHD5\": \"Perilipin-1\",\n",
        "    \"Peroxisome proliferator-activated receptor gamma/Nuclear receptor coactivator 1\": \"Peroxisome proliferator-activated receptor gamma\",\n",
        "    \"Peroxisome proliferator-activated receptor gamma/Nuclear receptor coactivator 2\": \"Peroxisome proliferator-activated receptor gamma\",\n",
        "    \"Peroxisome proliferator-activated receptor gamma/Nuclear receptor coactivator 3\": \"Peroxisome proliferator-activated receptor gamma\",\n",
        "    \"Peroxisome proliferator-activated receptor gamma/Nuclear receptor corepressor 2\": \"Peroxisome proliferator-activated receptor gamma\",\n",
        "    \"RAC1/TIAM1\": \"RAC1\",\n",
        "    \"RANKL/RANK\": \"RANKL\",\n",
        "    \"Rad51/BRCA2\": \"Rad51\",\n",
        "    \"Ras and Rab interactor 1/Tyrosine-protein kinase ABL1\": \"Ras and Rab interactor 1\",\n",
        "    \"Runt-related transcription factor 1/Core-binding factor subunit beta\": \"Runt-related transcription factor 1\",\n",
        "    \"S100B/p53\": \"S100B\",\n",
        "    \"SOD1 dimer\": \"SOD1\",\n",
        "    \"TNFA/TNFA\": \"TNFA\",\n",
        "    \"TNFR1A/TNFB\": \"TNFR1A\",\n",
        "    \"Transthyretin tetramer\": \"Transthyretin\",\n",
        "    \"Tubulin dimer\": \"Tubulin\",\n",
        "    \"Uncategorized\": \"Uncategorized\",\n",
        "    \"VEGF/VEGFR\": \"VEGF\",\n",
        "    \"VHL/HIF1A\": \"VHL\",\n",
        "    \"Voltage-gated N-type calcium channel alpha-1B subunit/Amyloid beta A4 precursor protein-binding family A member 1\": \"Voltage-gated N-type calcium channel alpha-1B subunit\",\n",
        "    \"WDR5/MLL1\": \"WDR5\",\n",
        "    \"WDR5/Mixed-lineage leukemia 1 (MLL1)\": \"WDR5\",\n",
        "    \"XDM2/P53\": \"XDM2\",\n",
        "    \"XIAP/SMAC\": \"XIAP\",\n",
        "    \"ZIPA/FTSZ\": \"ZIPA\",\n",
        "    \"p53/MDMX\": \"p53\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5XjF0jGKW5wA"
      },
      "outputs": [],
      "source": [
        "def get_other_folders(protein_target,protein_folder):\n",
        "    return [\n",
        "        d\n",
        "        for d in os.listdir(protein_folder)\n",
        "        if os.path.isdir(os.path.join(protein_target, d)) and d != target_name\n",
        "    ]\n",
        "\n",
        "def write_to_output(compound_path, prot1,prot2, label, training_data_path):\n",
        "    with open(training_data_path, \"a\") as output:\n",
        "        output.write(f\"{compound_path}\\t{prot1}\\t{prot2}\\t{label}\\n\")\n",
        "\n",
        "def get_pairs(protein_folder):\n",
        "    folder_name = protein_folder.split(',')\n",
        "    list1 = []\n",
        "    list2 = []\n",
        "    pairs = []\n",
        "    for file in os.listdir(f\"{protein_folder}/{folder_name[0]}\"):\n",
        "        list1.append(file)\n",
        "    for file in os.listdir(f\"{protein_folder}/{folder_name[1]}\"):\n",
        "        list2.append(file)\n",
        "    for a in list1:\n",
        "        for b in list2:\n",
        "            pairs.append([a,b])\n",
        "    return pairs\n",
        "\n",
        "def create_positive_samples(compound_path,protein_path,num_samples,training_data_path,activity=1):\n",
        "    # code to create the pairs\n",
        "    pairs = []\n",
        "    pairs = get_pairs(protein_path)\n",
        "    # writing to txt\n",
        "    random.shuffle(pairs)\n",
        "    cnt_to_add = min(num_samples,len(pairs))\n",
        "    for i in range(cnt_to_add):\n",
        "        write_to_output(compound_path,pairs[i][0],pairs[i][1],activity,training_data_path)\n",
        "\n",
        "def create_mismatch_samples(compound_path,protein_path,num_samples,protein_folder,training_data_path):\n",
        "    # code to create the pairs \n",
        "    other_folders = get_other_folders(protein_target=protein_path,protein_folder = protein_folder)\n",
        "    random_other_folders = random.sample(other_folders,num_samples)\n",
        "    pairs = []\n",
        "    for protein in random_other_folders:\n",
        "        folder_pairs = get_pairs(protein)\n",
        "        pairs.append(folder_pairs)\n",
        "    # writing to txt\n",
        "    random.shuffle(pairs)\n",
        "    cnt_to_add = min(num_samples,len(pairs))\n",
        "    for i in range(cnt_to_add):\n",
        "        write_to_output(compound_path,pairs[i][0],pairs[i][1],0,training_data_path)\n",
        "\n",
        "\n",
        "def process_csv_file(csv_path,compound_folder,protein_folder,training_data_path,using_targets_list):\n",
        "    target_name = None\n",
        "    inchikey = None\n",
        "    num_positive_samples = 10\n",
        "    num_negative_samples = 10\n",
        "\n",
        "    df = pd.read_csv(csv_path, header=None)\n",
        "    target_name_table = df[df[0] == \"Common Target Pref Name\"]\n",
        "    if not target_name_table.empty:\n",
        "        target_name = target_name_table.iloc[0, 1]\n",
        "    inchikey_table = df[df[0] == \"Standard Inchi Key(RDKit)\"]\n",
        "    if not inchikey_table.empty:\n",
        "        inchikey = inchikey_table.iloc[0, 1]\n",
        "    '''\n",
        "    Correct match\n",
        "    Mismatch\n",
        "    Negative sample\n",
        "    '''\n",
        "\n",
        "    if target_name is not None and inchikey is not None and target_name in using_targets_list:\n",
        "        # print(f\"target_name={target_name}, inchikey={inchikey}\")\n",
        "        matches += 1\n",
        "        compound_path = f\"{compound_folder}/{inchikey}.pdb\"\n",
        "        protein_path = f\"{protein_folder}/{target_name}\"\n",
        "        create_positive_samples(compound_path,protein_path,num_positive_samples,\"positive_samples.txt\")\n",
        "        create_mismatch_samples(compound_path,protein_path,num_negative_samples,protein_folder,\"mismatch_samples.txt\")\n",
        "\n",
        "def process_csv_file_inactive(csv_path,compound_folder,protein_folder):\n",
        "    target_name = None\n",
        "    inchikey = None\n",
        "    num_positive_samples = 10\n",
        "\n",
        "    df = pd.read_csv(csv_path, header=None)\n",
        "    target_name_table = df[df[0] == \"Common Target Pref Name\"]\n",
        "    if not target_name_table.empty:\n",
        "        target_name = target_name_table.iloc[0, 1]\n",
        "    inchikey_table = df[df[0] == \"Standard Inchi Key(RDKit)\"]\n",
        "    if not inchikey_table.empty:\n",
        "        inchikey = inchikey_table.iloc[0, 1]\n",
        "\n",
        "    if target_name is not None and inchikey is not None and target_name in using_targets_list:\n",
        "        # print(f\"target_name={target_name}, inchikey={inchikey}\")\n",
        "        matches += 1\n",
        "        compound_path = f\"{compound_folder}/{inchikey}.pdb\"\n",
        "        protein_path = f\"{protein_folder}/{target_name}\"\n",
        "        create_positive_samples(compound_path,protein_path,num_positive_samples,\"positive_samples.txt\",activity=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmlCMA4NR7_q",
        "outputId": "bb6b6376-8e6e-4f86-c6e7-fc7fd4267214"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "training_data_path = \"training_data.txt\"\n",
        "protein_folder = \"protein_files\"\n",
        "compound_folder = \"sdf_files\"\n",
        "csv_folder = \"dlip_files\"\n",
        "\n",
        "for filename in os.listdir(csv_folder):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(csv_folder, filename)\n",
        "        process_csv_file(csv_path,\n",
        "                         compound_folder=compound_folder,\n",
        "                         protein_folder=protein_folder,\n",
        "                         training_data_path=training_data_path,\n",
        "                         using_targets_list=using_targets_list\n",
        "                        )\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt6FABfonXcP"
      },
      "source": [
        "#create protein embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KthOZ6I-fVh6"
      },
      "outputs": [],
      "source": [
        "from shutil import unregister_archive_format\n",
        "\n",
        "class ProteinProteinInteractionPrediction(nn.Module):\n",
        "    def __init__(self,dim=20,layer_gnn=2,use_chem = True,use_prot = True):\n",
        "        super(ProteinProteinInteractionPrediction, self).__init__()\n",
        "        self.embed_fingerprint = nn.Embedding(n_fingerprint, dim)\n",
        "        self.W_gnn = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer_gnn)])\n",
        "        self.W1_attention = nn.Linear(dim, dim)\n",
        "        self.W2_attention = nn.Linear(dim, dim)\n",
        "        self.w = nn.Parameter(torch.zeros(dim))\n",
        "\n",
        "        self.use_chem = use_chem\n",
        "        self.use_prot = use_prot\n",
        "        # self.W_out = nn.Linear(90, 2)\n",
        "        self.W_out = nn.Sequential(\n",
        "            nn.Linear(350, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 2)\n",
        "        )\n",
        "\n",
        "    def gnn(self, xs1, A1, xs2, A2):\n",
        "        for i in range(layer_gnn):\n",
        "            hs1 = torch.relu(self.W_gnn[i](xs1))\n",
        "            hs2 = torch.relu(self.W_gnn[i](xs2))\n",
        "\n",
        "            xs1 = torch.matmul(A1, hs1)\n",
        "            xs2 = torch.matmul(A2, hs2)\n",
        "\n",
        "        return xs1, xs2\n",
        "\n",
        "    def mutual_attention(self, h1, h2):\n",
        "        x1 = self.W1_attention(h1)\n",
        "        x2 = self.W2_attention(h2)\n",
        "\n",
        "        m1 = x1.size()[0]\n",
        "        m2 = x2.size()[0]\n",
        "\n",
        "        c1 = x1.repeat(1, m2).view(m1, m2, dim)\n",
        "        c2 = x2.repeat(m1, 1).view(m1, m2, dim)\n",
        "\n",
        "        d = torch.tanh(c1 + c2)\n",
        "        alpha = torch.matmul(d, self.w).view(m1, m2)\n",
        "\n",
        "        b1 = torch.mean(alpha, 1)\n",
        "        p1 = torch.softmax(b1, 0)\n",
        "        s1 = torch.matmul(torch.t(x1), p1).view(-1, 1)\n",
        "\n",
        "        b2 = torch.mean(alpha, 0)\n",
        "        p2 = torch.softmax(b2, 0)\n",
        "        s2 = torch.matmul(torch.t(x2), p2).view(-1, 1)\n",
        "\n",
        "        return torch.cat((s1, s2), 0).view(1, -1), p1, p2\n",
        "\n",
        "    def forward(self, inputs, train = True):\n",
        "        fingerprints1, adjacency1, fingerprints2, adjacency2, chem = inputs\n",
        "        if chem.size(0) > 50:\n",
        "            chem = chem[:50]\n",
        "        elif chem.size(0) < 50:\n",
        "            zeros = torch.zeros(50 - chem.size(0), dtype=chem.dtype, device=chem.device)\n",
        "            chem = torch.cat((chem, zeros))\n",
        "\n",
        "        \"\"\"Protein vector with GNN.\"\"\"\n",
        "        x_fingerprints1 = self.embed_fingerprint(fingerprints1)\n",
        "        x_fingerprints2 = self.embed_fingerprint(fingerprints2)\n",
        "\n",
        "        x_protein1, x_protein2 = self.gnn(\n",
        "            x_fingerprints1, adjacency1, x_fingerprints2, adjacency2\n",
        "        )\n",
        "\n",
        "        \"\"\"Protein vector with mutual-attention.\"\"\"\n",
        "        y, p1, p2 = self.mutual_attention(x_protein1, x_protein2)\n",
        "        # chem = chem.unsqueeze(1)\n",
        "        # chem = chem.expand(-1, y.size(1))\n",
        "        # print(y.shape)\n",
        "        # print(chem.shape)\n",
        "        target_shape = (1,350)\n",
        "        chem = chem.reshape(1,-1)\n",
        "        chem = chem.float()\n",
        "        if self.use_chem and self.use_prot:\n",
        "            res = torch.cat((y,chem),dim=1)\n",
        "        elif self.use_prot:\n",
        "            res = y\n",
        "            padding = target_shape[1] - y.shape[1]\n",
        "            res = torch.nn.functional.pad(res, (0, padding))\n",
        "        elif self.use_chem:\n",
        "            res = chem\n",
        "            padding = target_shape[1] - chem.shape[1]\n",
        "            res = torch.nn.functional.pad(res, (0, padding))\n",
        "\n",
        "        z_interaction = self.W_out(res)\n",
        "        # ADD CHEMICAL FEATURE VECTOR HERE \n",
        "        return z_interaction, p1, p2\n",
        "\n",
        "    def __call__(self, data, train=True):\n",
        "        inputs, t_interaction = data[:-1], data[-1]\n",
        "        # if train:\n",
        "        #     z_interaction, p1, p2 = self.forward(inputs, train)\n",
        "        # else:\n",
        "        #     z_interaction, p1, p2, y = self.forward(inputs, train)\n",
        "        z_interaction, p1, p2 = self.forward(inputs, train)\n",
        "        # original_length = t_interaction.shape[0]\n",
        "        # t_interaction = torch.LongTensor(np.random.uniform(0,1, size=(original_length,)))\n",
        "        # print(t_interaction)\n",
        "        if train:\n",
        "            loss = F.cross_entropy(z_interaction, t_interaction)\n",
        "            return loss\n",
        "        else:\n",
        "            z = F.softmax(z_interaction, 1).to(\"cpu\").data[0].numpy()\n",
        "            if t_interaction.nelement() != 0:\n",
        "                t = int(t_interaction.to(\"cpu\").data[0].numpy())\n",
        "            else:\n",
        "                t = None  # or any other value you want to assign when `t_interaction` is empty\n",
        "                print(\"empty wahahahaha\")\n",
        "            return z, t, p1, p2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zl2ZHkmnZG5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csUhcSR7nZTk"
      },
      "source": [
        "#create modulator embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkiq-K_HnadO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq6FN0Pznaje"
      },
      "source": [
        "#train script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVxtY4rneYZ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "promisegat3env",
      "language": "python",
      "name": "promisegat3env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
